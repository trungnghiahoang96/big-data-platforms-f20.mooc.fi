{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"ModelTraining\")\n",
    "    .config(\"spark.executor.memory\", \"4g\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "schema = \"polarity FLOAT, id LONG, date_time TIMESTAMP, query STRING, user STRING, text STRING\"\n",
    "IN_PATH = \"/home/jovyan/data-sets/sentiment-140-training-data/CLEAN\"\n",
    "OUT_PATH = \"/home/jovyan/data-sets/sentiment-140-training-data/MODEL\"\n",
    "\n",
    "spark_reader = spark.read.schema(schema)\n",
    "\n",
    "df = spark_reader.parquet(IN_PATH)\n",
    "df = (\n",
    "    df\n",
    "    # Remove all numbers\n",
    "    .withColumn(\"text\", f.regexp_replace(f.col(\"text\"), \"[^a-zA-Z']\", \" \"))\n",
    "    # Remove all double/multiple spaces\n",
    "    .withColumn(\"text\", f.regexp_replace(f.col(\"text\"), \" +\", \" \"))\n",
    "    # Remove leading and trailing whitespaces\n",
    "    .withColumn(\"text\", f.trim(f.col(\"text\")))\n",
    "    # Ensure we don't end up with empty rows\n",
    "    .filter(\"text != ''\")\n",
    ")\n",
    "\n",
    "data = df.select(\"text\", \"polarity\").coalesce(3).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_data, validation_data, test_data) = data.randomSplit([0.98, 0.01, 0.01], seed=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 158 ms, sys: 36.2 ms, total: 195 ms\n",
      "Wall time: 464 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.ml.feature import (\n",
    "    StopWordsRemover,\n",
    "    Tokenizer,\n",
    "    HashingTF,\n",
    "    IDF,\n",
    ")\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words1\")\n",
    "stopwords_remover = StopWordsRemover(\n",
    "    inputCol=\"words1\",\n",
    "    outputCol=\"words2\",\n",
    "    stopWords=StopWordsRemover.loadDefaultStopWords(\"english\")\n",
    ")\n",
    "hashing_tf = HashingTF(\n",
    "    inputCol=\"words2\",\n",
    "    outputCol=\"term_frequency\",\n",
    ")\n",
    "idf = IDF(\n",
    "    inputCol=\"term_frequency\",\n",
    "    outputCol=\"features\",\n",
    "    minDocFreq=5,\n",
    ")\n",
    "lr = LogisticRegression(labelCol=\"polarity\")\n",
    "\n",
    "semantic_analysis_pipeline = Pipeline(\n",
    "    stages=[tokenizer, stopwords_remover, hashing_tf, idf, lr]\n",
    ")\n",
    "\n",
    "#semantic_analysis_model = semantic_analysis_pipeline.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|                text|polarity|              words1|              words2|      term_frequency|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|  ' ' cute hug facey|     0.0|[', ', cute, hug,...|[', ', cute, hug,...|(262144,[23837,92...|(262144,[23837,92...|[8.11128118607166...|[0.48221068785989...|       4.0|\n",
      "|' ' i didn't mean...|     0.0|[', ', i, didn't,...|[', ', mean, anyt...|(262144,[991,3710...|(262144,[991,3710...|[9.44175669178636...|[0.92914747544691...|       0.0|\n",
      "|' ' it's a monkey...|     4.0|[', ', it's, a, m...|[', ', monkey, re...|(262144,[36200,60...|(262144,[36200,60...|[9.04815777628548...|[0.85752678521703...|       0.0|\n",
      "|' And she broke m...|     0.0|[', and, she, bro...|   [', broke, heart]|(262144,[92047,10...|(262144,[92047,10...|[9.14819224140936...|[0.88145221538831...|       0.0|\n",
      "|' But u were doin...|     0.0|[', but, u, were,...|[', u, something,...|(262144,[80680,92...|(262144,[80680,92...|[7.57272503959815...|[0.24108547631135...|       4.0|\n",
      "|' CRAZY IN LOVE I...|     0.0|[', crazy, in, lo...|[', crazy, love, ...|(262144,[92047,17...|(262144,[92047,17...|[7.08592657574225...|[0.10683060165750...|       4.0|\n",
      "|                 ' D|     0.0|              [', d]|              [', d]|(262144,[27526,92...|(262144,[27526,92...|[8.04040833985041...|[0.44820483516250...|       4.0|\n",
      "|' HEY YOU It's So...|     4.0|[', hey, you, it'...|[', hey, somaya, ...|(262144,[24918,26...|(262144,[24918,26...|[6.91039528474626...|[0.07670845739391...|       4.0|\n",
      "|' I am really tin...|     0.0|[', i, am, really...|[', really, tiny,...|(262144,[14,23837...|(262144,[14,23837...|[7.62059765644313...|[0.25805735863259...|       4.0|\n",
      "|' I believe in yo...|     4.0|[', i, believe, i...|[', believe, love...|(262144,[92047,11...|(262144,[92047,11...|[6.56332742833479...|[0.04007570533599...|       4.0|\n",
      "|   ' I cry for Heath|     0.0|[', i, cry, for, ...|     [', cry, heath]|(262144,[83897,92...|(262144,[83897,92...|[9.65900142141515...|[0.95382182358426...|       0.0|\n",
      "|' I haven't got a...|     0.0|[', i, haven't, g...|[', got, decent, ...|(262144,[31463,53...|(262144,[31463,53...|[8.08142282260806...|[0.46515281830123...|       4.0|\n",
      "|' I realy wana cr...|     0.0|[', i, realy, wan...|[', realy, wana, ...|(262144,[31950,43...|(262144,[31950,43...|[9.62582748590687...|[0.94940978334809...|       0.0|\n",
      "|' I totally forgo...|     0.0|[', i, totally, f...|[', totally, forg...|(262144,[89663,92...|(262144,[89663,92...|[8.75409860576438...|[0.77128935802592...|       0.0|\n",
      "|' I've been missi...|     0.0|[', i've, been, m...|[', missing, true...|(262144,[92047,20...|(262144,[92047,20...|[9.17198148388856...|[0.88617495125199...|       0.0|\n",
      "|' I've had my pho...|     0.0|[', i've, had, my...|[', phone, wif, w...|(262144,[31463,92...|(262144,[31463,92...|[8.81823602606339...|[0.79128458973670...|       0.0|\n",
      "| ' LAW OF ATTRACTION|     4.0|[', law, of, attr...|[', law, attraction]|(262144,[19003,92...|(262144,[19003,92...|[7.73912311522756...|[0.30745903679567...|       4.0|\n",
      "|' MY SUNGLASSSSSS...|     0.0|[', my, sunglasss...|[', sunglasssssss...|(262144,[92047,19...|(262144,[92047,19...|[8.07754599852299...|[0.46704952536319...|       4.0|\n",
      "|  ' Thestreetforce '|     4.0|[', thestreetforc...|[', thestreetforc...|(262144,[92047,21...|(262144,[92047,21...|[7.91469720212732...|[0.38669924921923...|       4.0|\n",
      "|' They're easier ...|     4.0|[', they're, easi...|[', easier, witho...|(262144,[8562,704...|(262144,[8562,704...|[8.67753459983778...|[0.74317857654588...|       0.0|\n",
      "+--------------------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|                text|polarity|              words1|              words2|      term_frequency|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|' Today I woke up...|     0.0|[', today, i, wok...|[', today, woke, ...|(262144,[75373,92...|(262144,[75373,92...|[9.92923180694191...|[0.97252824118948...|       0.0|\n",
      "|' We'll miss ye f...|     4.0|[', we'll, miss, ...|[', miss, ye, sum...|(262144,[8443,218...|(262144,[8443,218...|[9.02852037099939...|[0.85148330437864...|       0.0|\n",
      "|'CRANKY' Oh oh ba...|     0.0|['cranky', oh, oh...|['cranky', oh, oh...|(262144,[23855,58...|(262144,[23855,58...|[8.23341128203349...|[0.54204891268949...|       0.0|\n",
      "|'Time Is An Illus...|     4.0|['time, is, an, i...|['time, illusion,...|(262144,[8443,535...|(262144,[8443,535...|[6.52119977522997...|[0.03691771757296...|       4.0|\n",
      "|'s boyfriend had ...|     0.0|['s, boyfriend, h...|['s, boyfriend, w...|(262144,[9168,343...|(262144,[9168,343...|[9.32512286439600...|[0.91247655749896...|       0.0|\n",
      "|'s boyfriend is g...|     0.0|['s, boyfriend, i...|['s, boyfriend, g...|(262144,[81948,17...|(262144,[81948,17...|[8.77030230666489...|[0.77657760254061...|       0.0|\n",
      "|A Congrats and ma...|     4.0|[a, congrats, and...|[congrats, many, ...|(262144,[91765,22...|(262144,[91765,22...|[6.34688065758123...|[0.02665079726518...|       4.0|\n",
      "|            A I know|     0.0|        [a, i, know]|              [know]|(262144,[140931],...|(262144,[140931],...|[8.00628552780356...|[0.43166342542476...|       4.0|\n",
      "|A Jonah more hugs...|     0.0|[a, jonah, more, ...|[jonah, hugs, ado...|(262144,[55882,10...|(262144,[55882,10...|[9.09215071332551...|[0.86867615562624...|       0.0|\n",
      "|A brought me BJ's...|     4.0|[a, brought, me, ...|[brought, bj's, p...|(262144,[15723,27...|(262144,[15723,27...|[8.13084072768372...|[0.49207505866175...|       4.0|\n",
      "|A central lesson ...|     0.0|[a, central, less...|[central, lesson,...|(262144,[27505,60...|(262144,[27505,60...|[8.13884294971551...|[0.49223180819948...|       4.0|\n",
      "|A colleague from ...|     0.0|[a, colleague, fr...|[colleague, thail...|(262144,[5381,912...|(262144,[5381,912...|[10.7965081679948...|[0.99496048233625...|       0.0|\n",
      "|A crap Thanks Sat...|     0.0|[a, crap, thanks,...|[crap, thanks, sa...|(262144,[25328,66...|(262144,[25328,66...|[8.23714673343472...|[0.54266679078946...|       0.0|\n",
      "|A few new swine c...|     0.0|[a, few, new, swi...|[new, swine, case...|(262144,[29945,12...|(262144,[29945,12...|[8.75255984695621...|[0.77043278880890...|       0.0|\n",
      "|   A froggy surprise|     4.0|[a, froggy, surpr...|  [froggy, surprise]|(262144,[188966,2...|(262144,[188966,2...|[7.60808575035167...|[0.25485225165812...|       4.0|\n",
      "|A jay kar just ga...|     4.0|[a, jay, kar, jus...|[jay, kar, gave, ...|(262144,[30444,42...|(262144,[30444,42...|[8.07539717435927...|[0.46363284720596...|       4.0|\n",
      "|A little buffalo ...|     4.0|[a, little, buffa...|[little, buffalo,...|(262144,[44587,15...|(262144,[44587,15...|[7.44010958630125...|[0.19545400003010...|       4.0|\n",
      "|A little wake up ...|     4.0|[a, little, wake,...|[little, wake, mu...|(262144,[13781,63...|(262144,[13781,63...|[7.59823341136554...|[0.25004652068055...|       4.0|\n",
      "|A neurologic inte...|     4.0|[a, neurologic, i...|[neurologic, inte...|(262144,[50660,96...|(262144,[50660,96...|[7.68203656158851...|[0.28035561927439...|       4.0|\n",
      "|A new day a new l...|     0.0|[a, new, day, a, ...|[new, day, new, l...|(262144,[13957,29...|(262144,[13957,29...|[9.06724966865572...|[0.86256698250418...|       0.0|\n",
      "+--------------------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|                text|polarity|              words1|              words2|      term_frequency|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|'I wanna love you...|     0.0|['i, wanna, love,...|['i, wanna, love,...|(262144,[1576,208...|(262144,[1576,208...|[8.75780038219738...|[0.76986477958864...|       0.0|\n",
      "|'Property photogr...|     0.0|['property, photo...|['property, photo...|(262144,[8379,341...|(262144,[8379,341...|[8.76556968987144...|[0.77370680228484...|       0.0|\n",
      "|'Seven Pounds' co...|     4.0|['seven, pounds',...|['seven, pounds',...|(262144,[15554,26...|(262144,[15554,26...|[8.22303146567468...|[0.53589074910828...|       0.0|\n",
      "|                   A|     0.0|                 [a]|                  []|      (262144,[],[])|      (262144,[],[])|[8.00495230315631...|[0.43148151327643...|       4.0|\n",
      "|A Lenny We'll mis...|     0.0|[a, lenny, we'll,...|[lenny, miss, cra...|(262144,[74200,16...|(262144,[74200,16...|[9.91260385814582...|[0.97165352699665...|       0.0|\n",
      "|A M goin to sleep...|     4.0|[a, m, goin, to, ...|[m, goin, sleep, ...|(262144,[18910,31...|(262144,[18910,31...|[8.39174307940308...|[0.61777079496130...|       0.0|\n",
      "|A little sad pret...|     0.0|[a, little, sad, ...|[little, sad, pre...|(262144,[49185,61...|(262144,[49185,61...|[10.8675521756116...|[0.99565629041615...|       0.0|\n",
      "|A little sore fro...|     0.0|[a, little, sore,...|[little, sore, fo...|(262144,[126368,1...|(262144,[126368,1...|[8.64863308749478...|[0.73197043135156...|       0.0|\n",
      "|A pleasant evenin...|     4.0|[a, pleasant, eve...|[pleasant, evenin...|(262144,[12531,13...|(262144,[12531,13...|[6.96905296149435...|[0.08537679789726...|       4.0|\n",
      "|A sad day for Bri...|     0.0|[a, sad, day, for...|[sad, day, britis...|(262144,[13957,21...|(262144,[13957,21...|[9.52608126163851...|[0.94048678800376...|       0.0|\n",
      "|A thanks for cari...|     4.0|[a, thanks, for, ...|[thanks, caring, ...|(262144,[14,30781...|(262144,[14,30781...|[7.00549695727181...|[0.09250895812199...|       4.0|\n",
      "|A thousand miles ...|     0.0|[a, thousand, mil...|[thousand, miles,...|(262144,[17004,12...|(262144,[17004,12...|[7.32961185159772...|[0.16298191843973...|       4.0|\n",
      "|A very relaxed ev...|     0.0|[a, very, relaxed...|[relaxed, evening...|(262144,[11951,13...|(262144,[11951,13...|[7.95728517686299...|[0.40475296340018...|       4.0|\n",
      "|A weekend full of...|     0.0|[a, weekend, full...|[weekend, full, e...|(262144,[66452,96...|(262144,[66452,96...|[8.97475409726775...|[0.83954266777521...|       0.0|\n",
      "|A'm loving Tyra B...|     4.0|[a'm, loving, tyr...|[a'm, loving, tyr...|(262144,[31463,66...|(262144,[31463,66...|[7.84706061919994...|[0.35377197172940...|       4.0|\n",
      "|AAAAHHHHHHHHH Tmr...|     0.0|[aaaahhhhhhhhh, t...|[aaaahhhhhhhhh, t...|(262144,[52505,94...|(262144,[52505,94...|[8.44679675654815...|[0.64534171874674...|       0.0|\n",
      "|              AGREED|     4.0|            [agreed]|            [agreed]|(262144,[222069],...|(262144,[222069],...|[7.79738461718933...|[0.33337143853677...|       4.0|\n",
      "|AHH I'm too in lo...|     0.0|[ahh, i'm, too, i...|    [ahh, love, two]|(262144,[15664,29...|(262144,[15664,29...|[7.49713133241175...|[0.21469220301255...|       4.0|\n",
      "|AHHH work Slow do...|     0.0|[ahhh, work, slow...|[ahhh, work, slow...|(262144,[24792,27...|(262144,[24792,27...|[9.16996230060374...|[0.88523054462484...|       0.0|\n",
      "|AHHHH EVERYTHINGS...|     0.0|[ahhhh, everythin...|[ahhhh, everythin...|(262144,[32890,40...|(262144,[32890,40...|[11.0525097180845...|[0.99695915702475...|       0.0|\n",
      "+--------------------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 183 ms, sys: 92.4 ms, total: 275 ms\n",
      "Wall time: 2.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "trained_df = semantic_analysis_model.transform(training_data)\n",
    "val_df = semantic_analysis_model.transform(validation_data)\n",
    "test_df = semantic_analysis_model.transform(test_data)\n",
    "\n",
    "trained_df.show()\n",
    "val_df.show()\n",
    "test_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.1 ms, sys: 1.41 ms, total: 3.52 ms\n",
      "Wall time: 16.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"polarity\", metricName=\"accuracy\")\n",
    "\n",
    "accuracy_val = evaluator.evaluate(val_df)\n",
    "accuracy_test = evaluator.evaluate(test_df)\n",
    "print(\"Validation Data:\")\n",
    "print(f\"Accuracy: {accuracy_val*100:.5f}%\")\n",
    "print(\"Testing Data:\")\n",
    "print(f\"Accuracy: {accuracy_test*100:.5f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.44201%\n",
      "CPU times: user 147 ms, sys: 83.2 ms, total: 231 ms\n",
      "Wall time: 3min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "final_model = semantic_analysis_pipeline.fit(data)\n",
    "\n",
    "accuracy_test = evaluator.evaluate(final_model.transform(test_data))\n",
    "print(f\"Accuracy: {accuracy_test*100:.5f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.save(OUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
