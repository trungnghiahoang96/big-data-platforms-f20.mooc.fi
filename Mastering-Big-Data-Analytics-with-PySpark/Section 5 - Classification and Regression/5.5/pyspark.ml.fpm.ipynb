{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequent Pattern Mining\n",
    "\n",
    "> __Note:__ marked as _experimental_\n",
    "\n",
    "Mining frequent items, itemsets, subsequences, or other substructures is usually among the first steps to analyze a large-scale dataset, which has been an active research topic in data mining for years.  \n",
    "See Wikipedia association rule learning for more information: \n",
    "https://en.wikipedia.org/wiki/Association_rule_learning\n",
    "\n",
    "\n",
    "## FPGrowth\n",
    "\n",
    "### `pyspark.ml.fpm.FPGrowth` and `pyspark.ml.fpm.FPGrowthModel`\n",
    "Spark's official documentation explains this one really well actually. To quote the API Guide:\n",
    "> A parallel FP-growth algorithm to mine frequent itemsets. The algorithm is described in [Li et al., PFP: Parallel FP-Growth for Query Recommendation LI2008](http://dx.doi.org/10.1145/1454008.1454027). PFP distributes computation in such a way that each worker executes an independent group of mining tasks. The FP-Growth algorithm is described in [Han et al., Mining frequent patterns without candidate generation HAN2000](http://dx.doi.org/10.1145/335191.335372)\n",
    "\n",
    "MLlib Main Guide: https://spark.apache.org/docs/2.4.3/ml-frequent-pattern-mining.html#fp-growth  \n",
    "Official API documentation: https://spark.apache.org/docs/2.4.3/api/python/pyspark.ml.html#module-pyspark.ml.fpm.FPGrowth\n",
    "\n",
    "Please navigate to the API guide and MLlib Main Guide to learn more about the FPGrowth and it's syntax.\n",
    "\n",
    "### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.fpm import FPGrowth\n",
    "\n",
    "data = [\n",
    "    (0, [1, 2, 5]),\n",
    "    (1, [1, 2, 3, 5]),\n",
    "    (2, [1, 2]),\n",
    "    (3, [1, 2, 5]),\n",
    "    (4, [1, 2, 3, 5]),\n",
    "    (5, [1, 2, 7]),\n",
    "    (6, [1, 2, 5]),\n",
    "    (7, [1, 2, 3, 5]),\n",
    "    (8, [1, 2, 4]),\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data, [\"id\", \"items\"],)\n",
    "\n",
    "fp_growth = FPGrowth(itemsCol=\"items\", minSupport=0.5, minConfidence=0.6)\n",
    "model = fp_growth.fit(df)\n",
    "\n",
    "# Display frequent itemsets.\n",
    "print(\"Frequent itemsets:\")\n",
    "model.freqItemsets.show()\n",
    "\n",
    "# Display generated association rules.\n",
    "print(\"Generated association rules\")\n",
    "model.associationRules.show()\n",
    "\n",
    "# transform examines the input items against all the association rules and summarize the\n",
    "# consequents as prediction\n",
    "print(\"Summary/Prediction:\")\n",
    "model.transform(df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PrefixSpan\n",
    "A parallel PrefixSpan algorithm to mine frequent sequential patterns. The PrefixSpan algorithm is described in [J. Pei, et al., PrefixSpan: Mining Sequential Patterns Efficiently by Prefix-Projected Pattern Growth](http://doi.org/10.1109/ICDE.2001.914830)\n",
    "\n",
    "### `pyspark.ml.fpm.PrefixSpan`\n",
    "\n",
    "> __Note:__ This class is not yet an Estimator/Transformer, use `.findFrequentSequentialPatterns()` method to run the `PrefixSpan` algorithm. This feature was newly added in Spark 2.4.0.\n",
    "\n",
    "Sequential Pattern Mining (Wikipedia): https://en.wikipedia.org/wiki/Sequential_Pattern_Mining  \n",
    "MLlib Main Guide: https://spark.apache.org/docs/2.4.3/ml-frequent-pattern-mining.html#prefixspan  \n",
    "Official API documentation: https://spark.apache.org/docs/2.4.3/api/python/pyspark.ml.html#pyspark.ml.fpm.PrefixSpan  \n",
    "\n",
    "Input data should be a DataFrame with an Array of Arrays. The example below shows how the data should look like.\n",
    "\n",
    "### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find Frequent Sequential Patterns:\n",
      "in:\n",
      "+---------------------+\n",
      "|sequence             |\n",
      "+---------------------+\n",
      "|[[1, 2], [3]]        |\n",
      "|[[1], [3, 2], [1, 2]]|\n",
      "|[[1, 2], [5]]        |\n",
      "|[[6]]                |\n",
      "+---------------------+\n",
      "\n",
      "out:\n",
      "+----------+----+\n",
      "|  sequence|freq|\n",
      "+----------+----+\n",
      "|     [[2]]|   3|\n",
      "|     [[3]]|   2|\n",
      "|     [[1]]|   3|\n",
      "|  [[1, 2]]|   3|\n",
      "|[[1], [3]]|   2|\n",
      "+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.fpm import PrefixSpan\n",
    "from pyspark.sql import Row\n",
    "\n",
    "data = [\n",
    "    Row(sequence=[[1, 2], [3]]),\n",
    "    Row(sequence=[[1], [3, 2], [1, 2]]),\n",
    "    Row(sequence=[[1, 2], [5]]),\n",
    "    Row(sequence=[[6]]),\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data, [\"sequence\"])\n",
    "print(\"Find Frequent Sequential Patterns:\")\n",
    "print(\"in:\")\n",
    "df.show(4, False)\n",
    "\n",
    "prefixSpan = PrefixSpan(minSupport=0.5, maxPatternLength=5, maxLocalProjDBSize=32000000)\n",
    "\n",
    "# Find frequent sequential patterns.\n",
    "# note: class is not yet an Estimator/Transformer, use .findFrequentSequentialPatterns() method to run\n",
    "print(\"out:\")\n",
    "prefixSpan.findFrequentSequentialPatterns(df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
